{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a869801",
   "metadata": {
    "papermill": {
     "duration": 120.229083,
     "end_time": "2025-05-17T20:27:51.695002",
     "exception": false,
     "start_time": "2025-05-17T20:25:51.465919",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "## Install Coqui TTS\n",
    "! pip install -U pip\n",
    "! pip install coqui-tts==0.26.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282d853",
   "metadata": {
    "papermill": {
     "duration": 0.024381,
     "end_time": "2025-05-17T20:27:51.744954",
     "exception": false,
     "start_time": "2025-05-17T20:27:51.720573",
     "status": "completed"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7392af6",
   "metadata": {
    "papermill": {
     "duration": 47.363405,
     "end_time": "2025-05-17T20:28:39.132212",
     "exception": false,
     "start_time": "2025-05-17T20:27:51.768807",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.bin.compute_embeddings import compute_embeddings\n",
    "from TTS.config import load_config\n",
    "from TTS.config.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.configs.vits_config import VitsConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.models.vits import CharactersConfig, Vits, VitsArgs, VitsAudioConfig\n",
    "from TTS.tts.utils.speakers import SpeakerManager\n",
    "from TTS.tts.utils.managers import save_file\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gdown\n",
    "import tarfile\n",
    "\n",
    "torch.set_num_threads(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd13b47",
   "metadata": {
    "papermill": {
     "duration": 0.03819,
     "end_time": "2025-05-17T20:28:39.365356",
     "exception": false,
     "start_time": "2025-05-17T20:28:39.327166",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "OUT_PATH = \"/kaggle/working/yourtts_tamazight\"\n",
    "LANG_NAME = \"tamazight\"\n",
    "ISO = \"zgh\"\n",
    "\n",
    "# Name of the run for the Trainer\n",
    "RUN_NAME = f\"YourTTS-{LANG_NAME.capitalize()}\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(OUT_PATH):\n",
    "    os.makedirs(OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ed74d2",
   "metadata": {
    "papermill": {
     "duration": 0.07443,
     "end_time": "2025-05-17T20:28:39.469957",
     "exception": false,
     "start_time": "2025-05-17T20:28:39.395527",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "# This paramter is useful to debug, it skips the training epochs and just do the evaluation  and produce the test sentences\n",
    "SKIP_TRAIN_EPOCH = False\n",
    "\n",
    "# Set here the batch size to be used in training and evaluation\n",
    "BATCH_SIZE = 40\n",
    "\n",
    "# Note: If you add new datasets, please make sure that the dataset sampling rate and this parameter are matching, otherwise resample your audios\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "# Max audio length in seconds to be used in training\n",
    "MAX_AUDIO_LEN_IN_SECONDS = 15\n",
    "# Min audio length in seconds to be used in training\n",
    "MIN_AUDIO_LEN_IN_SECONDS = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54cca4b",
   "metadata": {
    "papermill": {
     "duration": 126.931338,
     "end_time": "2025-05-17T20:30:46.425791",
     "exception": false,
     "start_time": "2025-05-17T20:28:39.494453",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "# If you want to do transfer learning and speedup your training you can set here the path to the CML-TTS available checkpoint that can be downloaded here:  https://drive.google.com/u/2/uc?id=1yDCSJ1pFZQTHhL09GMbOrdjcPULApa0p\n",
    "RESTORE_PATH = os.path.join(OUT_PATH, \"checkpoints_yourtts_cml_tts_dataset/best_model.pth\")\n",
    "\n",
    "URL = \"https://drive.google.com/u/2/uc?id=1yDCSJ1pFZQTHhL09GMbOrdjcPULApa0p\"\n",
    "OUTPUT_CHECKPOINTS_FILEPATH = os.path.join(OUT_PATH, \"checkpoints_yourtts_cml_tts_dataset.tar.bz\")\n",
    "\n",
    "# Download the CML-TTS checkpoint if it does not exist\n",
    "if not os.path.exists(RESTORE_PATH):\n",
    "    print(f\"Downloading the CML-TTS checkpoint from {URL}\")\n",
    "    gdown.download(url=URL, output=OUTPUT_CHECKPOINTS_FILEPATH, quiet=False, fuzzy=True)\n",
    "    with tarfile.open(OUTPUT_CHECKPOINTS_FILEPATH, \"r:bz2\") as tar:\n",
    "        tar.extractall(OUT_PATH)\n",
    "else:\n",
    "    print(f\"Checkpoint already exists at {RESTORE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e04dfff",
   "metadata": {
    "papermill": {
     "duration": 0.033911,
     "end_time": "2025-05-17T20:30:46.495696",
     "exception": false,
     "start_time": "2025-05-17T20:30:46.461785",
     "status": "completed"
    }
   },
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624343cc",
   "metadata": {
    "papermill": {
     "duration": 193.596359,
     "end_time": "2025-05-17T20:34:00.125933",
     "exception": false,
     "start_time": "2025-05-17T20:30:46.529574",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "ds = load_dataset(\"HackAI-2025/tts_dataset_30h\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5fd538",
   "metadata": {
    "papermill": {
     "duration": 0.048904,
     "end_time": "2025-05-17T20:34:00.212143",
     "exception": false,
     "start_time": "2025-05-17T20:34:00.163239",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5222c056",
   "metadata": {
    "papermill": {
     "duration": 0.064889,
     "end_time": "2025-05-17T20:34:00.312468",
     "exception": false,
     "start_time": "2025-05-17T20:34:00.247579",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "# Listen to a random sample\n",
    "import IPython\n",
    "import random\n",
    "\n",
    "random_index = random.randint(0, len(ds))\n",
    "sample = ds[random_index]\n",
    "print(\"Transcription: \", sample['text'])\n",
    "print(\"Duration: \", sample['duration'])\n",
    "IPython.display.Audio(sample['audio']['array'], rate=sample['audio']['sampling_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffcfa66",
   "metadata": {
    "papermill": {
     "duration": 0.053667,
     "end_time": "2025-05-17T20:34:00.404203",
     "exception": false,
     "start_time": "2025-05-17T20:34:00.350536",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "# Get statistics about the duration of audio files\n",
    "durations = ds['duration']\n",
    "print(\"Average duration: \", sum(durations) / len(durations))\n",
    "print(\"Max duration: \", max(durations))\n",
    "print(\"Min duration: \", min(durations))\n",
    "print(f\"Total duration in hours: {sum(durations) / 3600:.2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317f9bef",
   "metadata": {
    "papermill": {
     "duration": 0.195712,
     "end_time": "2025-05-17T20:34:00.638401",
     "exception": false,
     "start_time": "2025-05-17T20:34:00.442689",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "# Get character count frequencies\n",
    "from collections import Counter\n",
    "\n",
    "def get_char_counts(ds):\n",
    "    all_text = ds['text']\n",
    "    char_counts = Counter(''.join(all_text))\n",
    "    # Sort\n",
    "    char_counts = dict(sorted(char_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "    return char_counts\n",
    "\n",
    "char_counts = get_char_counts(ds)\n",
    "char_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a948970b",
   "metadata": {
    "papermill": {
     "duration": 0.045126,
     "end_time": "2025-05-17T20:34:00.723892",
     "exception": false,
     "start_time": "2025-05-17T20:34:00.678766",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "PUNCT = set(' !,.:?')\n",
    "\n",
    "CHARS = char_counts.keys()\n",
    "CHARS = set(CHARS)\n",
    "\n",
    "# Remove punctuation from character set\n",
    "CHARS = CHARS - PUNCT\n",
    "CHARS = sorted(list(CHARS))\n",
    "PUNCT = sorted(list(PUNCT))\n",
    "\n",
    "print(\"Punctuation: \", PUNCT)\n",
    "print(\"Character set: \", CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d1fdaa",
   "metadata": {
    "papermill": {
     "duration": 0.043965,
     "end_time": "2025-05-17T20:34:00.805772",
     "exception": false,
     "start_time": "2025-05-17T20:34:00.761807",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "# Create character config\n",
    "from TTS.tts.configs.shared_configs import CharactersConfig\n",
    "\n",
    "characters = CharactersConfig(\n",
    "    characters_class=\"TTS.tts.models.vits.VitsCharacters\",\n",
    "    pad=\"_\",\n",
    "    eos=\"&\",\n",
    "    bos=\"*\",\n",
    "    blank=None,\n",
    "    characters=\"\".join(CHARS),\n",
    "    punctuations=\"\".join(PUNCT),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2608fa8b",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 182.160534,
     "end_time": "2025-05-17T20:37:03.013445",
     "exception": false,
     "start_time": "2025-05-17T20:34:00.852911",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "output_dir = \"/kaggle/temp/zgh_tts_dataset\"\n",
    "wavs_dir = os.path.join(output_dir, \"wavs\")\n",
    "os.makedirs(wavs_dir, exist_ok=True)\n",
    "\n",
    "# Create the metadata file\n",
    "metadata_file = os.path.join(output_dir, \"metadata.csv\")\n",
    "metadata = []\n",
    "\n",
    "# Iterate over the dataset\n",
    "for i, sample in tqdm(enumerate(ds), total=len(ds)):\n",
    "    # Get the audio data and text\n",
    "    audio_array = sample['audio']['array']\n",
    "    text = sample['text']\n",
    "\n",
    "    # Create a unique file name\n",
    "    file_name_no_ext = f\"{i:05d}\"\n",
    "    file_name = f\"{file_name_no_ext}.wav\"\n",
    "    file_path = os.path.join(wavs_dir, file_name)\n",
    "\n",
    "    # Save the audio file at 22050 Hz\n",
    "    sf.write(file_path, audio_array, 22050)\n",
    "\n",
    "    # Append to the metadata\n",
    "    metadata.append(f\"wavs/{file_name}||{text}|yan|\")\n",
    "\n",
    "# Write the metadata to the csv file\n",
    "with open(metadata_file, 'w') as f:\n",
    "  for line in metadata:\n",
    "    f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bddcd0",
   "metadata": {
    "papermill": {
     "duration": 0.293181,
     "end_time": "2025-05-17T20:37:03.404646",
     "exception": false,
     "start_time": "2025-05-17T20:37:03.111465",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "!ls -lh $output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84bb5ad",
   "metadata": {
    "papermill": {
     "duration": 0.28247,
     "end_time": "2025-05-17T20:37:03.785931",
     "exception": false,
     "start_time": "2025-05-17T20:37:03.503461",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "!head $output_dir/metadata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553bd685",
   "metadata": {
    "papermill": {
     "duration": 0.103963,
     "end_time": "2025-05-17T20:37:04.040071",
     "exception": false,
     "start_time": "2025-05-17T20:37:03.936108",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "dataset_conf = BaseDatasetConfig(\n",
    "    formatter=\"brspeech\", meta_file_train=\"metadata.csv\", path=output_dir, dataset_name=\"zgh_tts_dataset\", language=ISO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5019112",
   "metadata": {
    "papermill": {
     "duration": 369.427756,
     "end_time": "2025-05-17T20:43:13.565832",
     "exception": false,
     "start_time": "2025-05-17T20:37:04.138076",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "### Extract speaker embeddings\n",
    "SPEAKER_ENCODER_CHECKPOINT_PATH = (\n",
    "    \"https://github.com/coqui-ai/TTS/releases/download/speaker_encoder_model/model_se.pth.tar\"\n",
    ")\n",
    "SPEAKER_ENCODER_CONFIG_PATH = \"https://github.com/coqui-ai/TTS/releases/download/speaker_encoder_model/config_se.json\"\n",
    "\n",
    "D_VECTOR_FILES = []  # List of speaker embeddings/d-vectors to be used during the training\n",
    "\n",
    "# Checks if the speakers embeddings are already computated, if not compute it\n",
    "embeddings_file = os.path.join(dataset_conf.path, \"speakers.pth\")\n",
    "if not os.path.isfile(embeddings_file):\n",
    "    print(f\">>> Computing the speaker embeddings for the {dataset_conf.dataset_name} dataset\")\n",
    "    compute_embeddings(\n",
    "        SPEAKER_ENCODER_CHECKPOINT_PATH,\n",
    "        SPEAKER_ENCODER_CONFIG_PATH,\n",
    "        embeddings_file,\n",
    "        formatter_name=dataset_conf.formatter,\n",
    "        dataset_name=dataset_conf.dataset_name,\n",
    "        dataset_path=dataset_conf.path,\n",
    "        meta_file_train=dataset_conf.meta_file_train,\n",
    "        meta_file_val=dataset_conf.meta_file_val,\n",
    "    )\n",
    "D_VECTOR_FILES.append(embeddings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a63cb",
   "metadata": {
    "papermill": {
     "duration": 0.229047,
     "end_time": "2025-05-17T20:43:14.072500",
     "exception": false,
     "start_time": "2025-05-17T20:43:13.843453",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "# Audio config used in training.\n",
    "audio_config = VitsAudioConfig(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    hop_length=256,\n",
    "    win_length=1024,\n",
    "    fft_size=1024,\n",
    "    mel_fmin=0.0,\n",
    "    mel_fmax=None,\n",
    "    num_mels=80,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02586b50",
   "metadata": {
    "papermill": {
     "duration": 0.226236,
     "end_time": "2025-05-17T20:43:14.521071",
     "exception": false,
     "start_time": "2025-05-17T20:43:14.294835",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "# Init VITSArgs setting the arguments that are needed for the YourTTS model\n",
    "model_args = VitsArgs(\n",
    "    spec_segment_size=62,\n",
    "    hidden_channels=192,\n",
    "    hidden_channels_ffn_text_encoder=768,\n",
    "    num_heads_text_encoder=2,\n",
    "    num_layers_text_encoder=10,\n",
    "    kernel_size_text_encoder=3,\n",
    "    dropout_p_text_encoder=0.1,\n",
    "    d_vector_file=D_VECTOR_FILES,\n",
    "    use_d_vector_file=True,\n",
    "    d_vector_dim=512,\n",
    "    speaker_encoder_model_path=SPEAKER_ENCODER_CHECKPOINT_PATH,\n",
    "    speaker_encoder_config_path=SPEAKER_ENCODER_CONFIG_PATH,\n",
    "    resblock_type_decoder=\"2\",  # In the paper, we accidentally trained the YourTTS using ResNet blocks type 2, if you like you can use the ResNet blocks type 1 like the VITS model\n",
    "    # Useful parameters to enable the Speaker Consistency Loss (SCL) described in the paper\n",
    "    use_speaker_encoder_as_loss=False,\n",
    "    # Useful parameters to enable multilingual training\n",
    "    use_language_embedding=True,\n",
    "    embedded_language_dim=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accf2c02",
   "metadata": {
    "papermill": {
     "duration": 0.22602,
     "end_time": "2025-05-17T20:43:14.996870",
     "exception": false,
     "start_time": "2025-05-17T20:43:14.770850",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "TEST_SENTENCES = [\n",
    "    [\"â´°âµ£âµ“âµ â´°âµ¢âµœâµŽâ´° â´· âµ‰âµ™âµ™âµœâµŽâ´°!\", \"yan\", None, \"zgh\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1527beb",
   "metadata": {
    "papermill": {
     "duration": 0.233569,
     "end_time": "2025-05-17T20:43:15.501363",
     "exception": false,
     "start_time": "2025-05-17T20:43:15.267794",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "# General training config, here you can change the batch size and others useful parameters\n",
    "config = VitsConfig(\n",
    "    epochs=25,\n",
    "    output_path=OUT_PATH,\n",
    "    model_args=model_args,\n",
    "    run_name=RUN_NAME,\n",
    "    project_name=\"YourTTS\",\n",
    "    run_description=f\"\"\"\n",
    "            - YourTTS trained using the {LANG_NAME.capitalize()} dataset.\n",
    "        \"\"\",\n",
    "    dashboard_logger=\"tensorboard\",\n",
    "    logger_uri=None,\n",
    "    audio=audio_config,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    batch_group_size=4,\n",
    "    eval_batch_size=BATCH_SIZE,\n",
    "    num_loader_workers=8,\n",
    "    # eval_split_max_size=256,\n",
    "    print_step=25,\n",
    "    plot_step=50,\n",
    "    # log_model_step=1000,\n",
    "    save_step=1000,\n",
    "    save_n_checkpoints=5,\n",
    "    save_checkpoints=True,\n",
    "    target_loss=\"loss_1\",\n",
    "    print_eval=True,\n",
    "    compute_input_seq_cache=True,\n",
    "    add_blank=True,\n",
    "    text_cleaner=\"no_cleaners\",\n",
    "    characters=characters,\n",
    "    phoneme_cache_path=None,\n",
    "    precompute_num_workers=12,\n",
    "    start_by_longest=True,\n",
    "    datasets=[dataset_conf],\n",
    "    cudnn_benchmark=False,\n",
    "    min_audio_len=int(SAMPLE_RATE * MIN_AUDIO_LEN_IN_SECONDS),\n",
    "    max_audio_len=SAMPLE_RATE * MAX_AUDIO_LEN_IN_SECONDS,\n",
    "    mixed_precision=True,\n",
    "    test_sentences=TEST_SENTENCES,\n",
    "    # Enable the weighted sampler\n",
    "    # use_weighted_sampler=True,\n",
    "    # Ensures that all speakers are seen in the training batch equally no matter how many samples each speaker has\n",
    "    # weighted_sampler_attrs={\"language\": 1.0, \"speaker_name\": 1.0},\n",
    "    # weighted_sampler_attrs={\"language\": 1.0},\n",
    "    # weighted_sampler_multipliers={\n",
    "    #     # \"speaker_name\": {\n",
    "    #     # you can force the batching scheme to give a higher weight to a certain speaker and then this speaker will appears more frequently on the batch.\n",
    "    #     # It will speedup the speaker adaptation process. Considering the CML train dataset and \"new_speaker\" as the speaker name of the speaker that you want to adapt.\n",
    "    #     # The line above will make the balancer consider the \"new_speaker\" as 106 speakers so 1/4 of the number of speakers present on CML dataset.\n",
    "    #     # 'new_speaker': 106, # (CML tot. train speaker)/4 = (424/4) = 106\n",
    "    #     # }\n",
    "    # },\n",
    "    # It defines the Speaker Consistency Loss (SCL) Î± to 9 like the YourTTS paper\n",
    "    speaker_encoder_loss_alpha=9.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f90093",
   "metadata": {
    "papermill": {
     "duration": 0.372324,
     "end_time": "2025-05-17T20:43:16.094068",
     "exception": false,
     "start_time": "2025-05-17T20:43:15.721744",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "# Load all the datasets samples and split traning and evaluation sets\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    config.datasets,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=config.eval_split_size,\n",
    ")\n",
    "print(f\"Loaded {len(train_samples)} train samples\")\n",
    "print(f\"Loaded {len(eval_samples)} eval samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1015038",
   "metadata": {
    "papermill": {
     "duration": 0.219303,
     "end_time": "2025-05-17T20:43:16.586457",
     "exception": false,
     "start_time": "2025-05-17T20:43:16.367154",
     "status": "completed"
    }
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c325d",
   "metadata": {
    "papermill": {
     "duration": 15.291496,
     "end_time": "2025-05-17T20:43:32.100264",
     "exception": false,
     "start_time": "2025-05-17T20:43:16.808768",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "# Init the model\n",
    "model = Vits.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c736c3",
   "metadata": {
    "papermill": {
     "duration": 35874.749619,
     "end_time": "2025-05-18T06:41:27.075025",
     "exception": false,
     "start_time": "2025-05-17T20:43:32.325406",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "# Init the trainer and ðŸš€\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(restore_path=RESTORE_PATH, skip_train_epoch=SKIP_TRAIN_EPOCH),\n",
    "    config,\n",
    "    output_path=OUT_PATH,\n",
    "    model=model,\n",
    "    train_samples=train_samples,\n",
    "    eval_samples=eval_samples,\n",
    ")\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16d5ee1",
   "metadata": {
    "papermill": {
     "duration": 0.315977,
     "end_time": "2025-05-18T06:41:27.701666",
     "exception": false,
     "start_time": "2025-05-18T06:41:27.385689",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "paths = sorted([f for f in glob.glob(OUT_PATH+\"/YourTTS*\")])\n",
    "#ckpts = sorted([f for f in glob.glob(OUT_PATH+\"/YourTTS*/best_model.pth\")])\n",
    "#configs = sorted([f for f in glob.glob(OUT_PATH+\"/YourTTS*/config.json\")])\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaaa72b",
   "metadata": {
    "papermill": {
     "duration": 0.313593,
     "end_time": "2025-05-18T06:41:28.325933",
     "exception": false,
     "start_time": "2025-05-18T06:41:28.012340",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "path = paths[-1]\n",
    "test_ckpt = os.path.join(path, \"best_model.pth\")\n",
    "test_config = os.path.join(path, \"config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0159e9",
   "metadata": {
    "papermill": {
     "duration": 52.155062,
     "end_time": "2025-05-18T06:42:20.789078",
     "exception": false,
     "start_time": "2025-05-18T06:41:28.634016",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "!tts --text \"â´°âµ£âµ“âµ â´°âµ¢âµœâµŽâ´° â´· âµ‰âµ™âµ™âµœâµŽâ´°!\" \\\n",
    "      --model_path $test_ckpt \\\n",
    "      --config_path $test_config \\\n",
    "      --speaker_idx yan \\\n",
    "      --out_path out.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d547bb70",
   "metadata": {
    "papermill": {
     "duration": 0.433326,
     "end_time": "2025-05-18T06:42:21.541520",
     "exception": false,
     "start_time": "2025-05-18T06:42:21.108194",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"out.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f66379",
   "metadata": {
    "papermill": {
     "duration": 6.391965,
     "end_time": "2025-05-18T06:42:28.249849",
     "exception": false,
     "start_time": "2025-05-18T06:42:21.857884",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "# Load the extension and start TensorBoard\n",
    "%load_ext tensorboard\n",
    "#%reload_ext tensorboard\n",
    "%tensorboard --logdir $OUT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e9a27",
   "metadata": {
    "papermill": {
     "duration": 0.306777,
     "end_time": "2025-05-18T06:42:28.873516",
     "exception": false,
     "start_time": "2025-05-18T06:42:28.566739",
     "status": "completed"
    }
   },
   "source": [
    "!curl -sSL https://ngrok-agent.s3.amazonaws.com/ngrok.asc \\\n",
    "  | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null \\\n",
    "  && echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" \\\n",
    "  | sudo tee /etc/apt/sources.list.d/ngrok.list \\\n",
    "  && sudo apt update \\\n",
    "  && sudo apt install ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9319c9",
   "metadata": {
    "papermill": {
     "duration": 0.317063,
     "end_time": "2025-05-18T06:42:29.501734",
     "exception": false,
     "start_time": "2025-05-18T06:42:29.184671",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "#!ngrok config add-authtoken 2wxfy0o2SaHiJQpWcTKawpLZ5jJ_4az7tDkNynTsk5LXe3nqv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9bdd0",
   "metadata": {
    "papermill": {
     "duration": 0.316241,
     "end_time": "2025-05-18T06:42:30.129633",
     "exception": false,
     "start_time": "2025-05-18T06:42:29.813392",
     "status": "completed"
    }
   },
   "outputs": [],
   "source": [
    "#!ngrok http 6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
