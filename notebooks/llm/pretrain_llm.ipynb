{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e56b6221",
      "metadata": {
        "id": "e56b6221"
      },
      "source": [
        "# Pre-Training Your First Language Model 🚀\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/1337-Artificial-Intelligence/hackai-2025/blob/main/new_notebooks/train_pretrain_smollm_goudma.ipynb)\n",
        "\n",
        "In this notebook, you'll learn how to train a small language model from scratch! We'll use the SmolLM2 model, which is perfect for learning because it's small but powerful."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31a36074",
      "metadata": {
        "id": "31a36074"
      },
      "source": [
        "## What is Language Model Training? 🤔\n",
        "\n",
        "> A language model is like a student learning to read and write. It learns by:\n",
        "> 1. Reading lots of text\n",
        "> 2. Trying to predict the next word in a sentence\n",
        "> 3. Learning from its mistakes\n",
        "\n",
        "```\n",
        "Example:\n",
        "Input: \"The cat sat on the\"\n",
        "Model predicts: \"mat\" (or \"chair\", \"table\", etc.)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "199199e2",
      "metadata": {
        "id": "199199e2"
      },
      "source": [
        "## Notebook outline\n",
        "![image.png](https://i.postimg.cc/9VJdcxCT/download-4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f56bb9c6",
      "metadata": {
        "id": "f56bb9c6"
      },
      "source": [
        "# Before You Start"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **What is Regular Pretraining (RPT)?**\n",
        "\n",
        "> The first step in creating a high-quality LLM is to pretrain it on one or more massive text datasets. During training, it attempts to **predict the next token** to accurately learn **linguistic** and **semantic** representations found in the text.\n",
        "this is called language modeling and is a **self-supervised** method.\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://postimage.me/images/2025/05/21/imagebaee1c6f904f7438.png\" width=600 />\n",
        "\n",
        "</center>\n",
        "\n",
        "> The purpose of pretraining a model on large datasets is that it is **able to reproduce language and its meaning**. During this process, the model learns to complete input phrases.\n",
        "\n",
        "> The pretraining stage produce to us **base model** and also called **foundation model**.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "🤗 huggingface Base models examples:\n",
        "\n",
        "- HuggingFaceTB/SmolLM2-135M\n",
        "- Qwen/Qwen2.5-0.5B\n",
        "- meta-llama/Llama-3.3-70B\n",
        "- mistralai/Mistral-7B-v0.3\n",
        "```"
      ],
      "metadata": {
        "id": "4w6pUa9WWg1-"
      },
      "id": "4w6pUa9WWg1-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Continued Pretraining (CPT)**\n",
        "\n",
        ">Continued or continual pretraining (CPT) is necessary to “steer” the language model to **understand new domains of knowledge**, or **out of distribution domains**. Base models like Llama-3 or Qwen are **first pretrained on gigantic datasets of trillions of tokens** (Llama-3 for eg is 15 trillion). But sometimes these models have **not been well trained on other languages (eg arabic, darija)**, or text specific domains, like **law, medicine or other areas**.\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://postimage.me/images/2025/05/21/imagebafd64ee157b29f7.png\" width=600 />\n",
        "</center>\n",
        "\n",
        "\n",
        "> Continued pretraining (CPT) is necessary to make the language model learn new tokens or datasets."
      ],
      "metadata": {
        "id": "3iaIsAAXW0n-"
      },
      "id": "3iaIsAAXW0n-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **What is Finetuning (SFT)?**\n",
        "\n",
        "> In this stage after we got our base model that's understand the languge, with **supervised finetuning (SFT**) we can adapt the base model ***to follow instructions***.\n",
        "\n",
        "> During SFT process the model parameters are **updated** to be more in line with out target task (eg Q/A.)\n",
        "\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://postimage.me/images/2025/05/21/image147c1adf116d4f4b.png\" width=600 />\n",
        "</center>\n",
        "\n",
        "> SFT training is like pretraining (trained using next-token prediction); the only difference is that SFT is **based on user input**.\n",
        "\n",
        "> After SFT of our base model we will get new model that's called **Instruction Model**\n",
        "\n",
        "```\n",
        "🤗 huggingface Instruct models examples:\n",
        "\n",
        "- HuggingFaceTB/SmolLM2-135M-Instruct\n",
        "- Qwen/Qwen2.5-0.5B-Instruct\n",
        "- meta-llama/Llama-3.3-70B-Instruct\n",
        "- mistralai/Mistral-7B-Instruct-v0.3\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "zMKSqs71Xll_"
      },
      "id": "zMKSqs71Xll_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "<img src=\"https://postimage.me/images/2025/05/21/imagee016e2fc7633535b.png\" width=600 />\n",
        "</center>\n",
        "\n",
        "\n",
        "> In the stage of pretraining your model you need a huge amount of unlabeled data (text)\n",
        "\n",
        "> In the finetuning stage you need labeled data (also called instruction dataset )"
      ],
      "metadata": {
        "id": "Yfy_saGrYGNn"
      },
      "id": "Yfy_saGrYGNn"
    },
    {
      "cell_type": "markdown",
      "id": "3aae22eb",
      "metadata": {
        "id": "3aae22eb"
      },
      "source": [
        "# Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97744e2c",
      "metadata": {
        "id": "97744e2c",
        "outputId": "03a66218-0ffd-455a-cfb9-49885828da87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install -U torch datasets transformers wandb -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a912b0f",
      "metadata": {
        "id": "9a912b0f"
      },
      "source": [
        "# Check GPU Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57f68569",
      "metadata": {
        "id": "57f68569",
        "outputId": "b5b3f322-59fe-43af-ee0e-9b8a56399197"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available() # True means you're using nvidia gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ffa6301",
      "metadata": {
        "id": "0ffa6301",
        "outputId": "d2da80bd-ae17-4d2c-8f04-f1480af705d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Mar 22 17:01:47 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8             10W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi # you can also use nvitop \"pip install nvitop\" to see real time gpu consumption in your terminal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a7e386c",
      "metadata": {
        "id": "7a7e386c"
      },
      "source": [
        "# Load Your Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5876050",
      "metadata": {
        "id": "f5876050"
      },
      "source": [
        "> In this section we will learn how to load our dataset from huggingface 🤗, select the column we want to train our model on, finallu split it to train/test.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e42deb89",
      "metadata": {
        "id": "e42deb89"
      },
      "source": [
        "1. huggingface loging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bade360a",
      "metadata": {
        "id": "bade360a"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "577f59fd",
      "metadata": {
        "id": "577f59fd"
      },
      "source": [
        "2. load dataset using `load_dataset`and the id of dataset from huggingface `username\\datasetname` example `atlasia\\atlaset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d874b657",
      "metadata": {
        "id": "d874b657"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7527092",
      "metadata": {
        "id": "d7527092",
        "outputId": "2b1a0d1d-639d-45bc-dc20-176120954b41",
        "colab": {
          "referenced_widgets": [
            "e3baf9ccc52f4bbca882aab8b4b586df",
            "780c9c809b67461ebca963402852e53e",
            "8f2b136d5fad482b954d924f6426143f"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3baf9ccc52f4bbca882aab8b4b586df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/338 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "780c9c809b67461ebca963402852e53e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f2b136d5fad482b954d924f6426143f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/6 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['titles', 'content', 'images'],\n",
              "    num_rows: 6\n",
              "})"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset_name_id=\"atlasia/good25\"\n",
        "ds=load_dataset(dataset_name_id,split=\"train\")\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "507a3f43",
      "metadata": {
        "id": "507a3f43",
        "outputId": "e2a037ee-e115-4770-dfda-55a9e1e39bd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['content'],\n",
              "    num_rows: 6\n",
              "})"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# select only the text columns (eg content) that's our model want to train on.\n",
        "ds=ds.select_columns([\"content\"])\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6f892fb",
      "metadata": {
        "id": "e6f892fb",
        "outputId": "ed121807-dd97-47de-c2df-05f05acc18ee"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"ds\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0623\\u0646\\u0633 \\u0627\\u0644\\u0639\\u0645\\u0631\\u064a \\u2013 \\u0643\\u0648\\u062f///\\n\\u0637\\u0627\\u0626\\u0631\\u0629 (Ak\\u0131nc\\u0131) \\u0628\\u062f\\u0648\\u0646 \\u0637\\u064a\\u0627\\u0631\\u060c \\u0644\\u064a \\u062d\\u0635\\u0644 \\u0639\\u0644\\u064a\\u0647\\u0627 \\u0627\\u0644\\u0645\\u063a\\u0631\\u0628 \\u0645\\u0624\\u062e\\u0631\\u0627\\u060c \\u062f\\u0627\\u064a\\u0631\\u0629 \\u0623\\u062f\\u0627\\u0621 \\u0627\\u0633\\u062a\\u0646\\u062b\\u0627\\u0626\\u064a. \\u0647\\u0627\\u062f \\u0627\\u0644\\u0637\\u0627\\u0626\\u0631\\u0629\\u060c \\u0644\\u064a \\u062a\\u0646\\u062a\\u062c\\u0647\\u0627 \\u0634\\u0631\\u0643\\u0629 \\u201c\\u0628\\u0627\\u064a\\u0643\\u0627\\u0631\\u201d \\u0627\\u0644\\u062a\\u0631\\u0643\\u064a\\u0629\\u060c \\u062d\\u0642\\u0642\\u0627\\u062a \\u0625\\u0646\\u062c\\u0627\\u0632 \\u0628\\u062a\\u062c\\u0627\\u0648\\u0632\\u0647\\u0627 100 \\u0623\\u0644\\u0641 \\u0633\\u0627\\u0639\\u0629 \\u0637\\u064a\\u0631\\u0627\\u0646.\\n\\u0648\\u0623\\u0643\\u062f\\u0627\\u062a \\u0634\\u0631\\u0643\\u0629 \\u201c\\u0628\\u0627\\u064a\\u0643\\u0627\\u0631\\u201d \\u0641\\u064a \\u0628\\u064a\\u0627\\u0646 \\u0646\\u0634\\u0631\\u062a\\u0647 \\u0623\\u0648\\u0644 \\u0623\\u0645\\u0633 \\u0627\\u0644\\u062b\\u0644\\u0627\\u062b\\u0627\\u0621\\u060c \\u0648\\u0646\\u0642\\u0644\\u062a\\u0647 \\u0648\\u0643\\u0627\\u0644\\u0629 \\u0627\\u0644\\u0623\\u0646\\u0627\\u0636\\u0648\\u0644\\u060c \\u0623\\u0646 \\u201c\\u0623\\u0643\\u064a\\u0646\\u062c\\u064a\\u201d \\u062d\\u0644\\u0642\\u062a \\u0644\\u0623\\u0643\\u062b\\u0631 \\u0645\\u0646 100 \\u0623\\u0644\\u0641 \\u0633\\u0627\\u0639\\u0629 \\u0641\\u064a \\u0627\\u0644\\u0645\\u062c\\u0627\\u0644 \\u0627\\u0644\\u062c\\u0648\\u064a \\u0627\\u0644\\u062a\\u0631\\u0643\\u064a\\u060c \\u0645\\u0628\\u0631\\u0632\\u0629 \\u0623\\u0646 \\u0645\\u0627 \\u062d\\u0642\\u0642\\u062a\\u0647 \\u201c\\u0631\\u0642\\u0645 \\u0642\\u064a\\u0627\\u0633\\u064a \\u0639\\u0627\\u0644\\u0645\\u064a\\u201d.\\n\\u0648\\u0630\\u0643\\u0631\\u062a \\u0627\\u0644\\u0634\\u0631\\u0643\\u0629 \\u0623\\u0646 \\u0647\\u0627\\u062f \\u0627\\u0644\\u0637\\u0627\\u0626\\u0631\\u0629 \\u0628\\u062f\\u0648\\u0646 \\u0637\\u064a\\u0627\\u0631 \\u0648\\u0635\\u0644\\u062a \\u0628\\u0627\\u0644\\u0641\\u0639\\u0644 \\u0625\\u0644\\u0649 \\u0627\\u0631\\u062a\\u0641\\u0627\\u0639 \\u0642\\u064a\\u0627\\u0633\\u064a \\u0628\\u0644\\u063a 45118 \\u0642\\u062f\\u0645\\u0627\\u060c \\u0645\\u0639\\u0644\\u0646\\u0629 \\u0623\\u0646\\u0647\\u0627 \\u201c\\u0648\\u0642\\u0639\\u062a \\u0639\\u0642\\u0648\\u062f \\u0634\\u0631\\u0627\\u0621 \\u0645\\u0639 11 \\u062f\\u0648\\u0644\\u0629\\u201d.\",\n          \"\\u0643\\u0648\\u062f \\u2013 \\u0643\\u0627\\u0632\\u0627 ///\\n\\u0642\\u0627\\u0644\\u062a \\u062c\\u0631\\u064a\\u062f\\u0629 \\u0623\\u0648\\u0643\\u062f\\u064a\\u0627\\u0631\\u064a\\u0648 \\u0627\\u0644\\u0625\\u0633\\u0628\\u0627\\u0646\\u064a\\u0629\\u060c \\u0625\\u0646 \\u0645\\u0628\\u064a\\u0639\\u0627\\u062a \\u0627\\u0644\\u0623\\u0633\\u0644\\u062d\\u0629 \\u0627\\u0644\\u0625\\u0633\\u0628\\u0627\\u0646\\u064a\\u0629 \\u0644\\u0644\\u0645\\u063a\\u0631\\u0628 \\u0632\\u0627\\u062f\\u062a\\u00a0 \\u0628\\u0646\\u0633\\u0628\\u0629 1264.77\\u066a \\u0641 \\u0639\\u0627\\u0645 2024 \\u0645\\u0642\\u0627\\u0631\\u0646\\u0629 \\u0628\\u0639\\u0627\\u0645 2023 \\u0623\\u0648 \\u0628\\u0639\\u0628\\u0627\\u0631\\u0629 \\u0623\\u062e\\u0631\\u0649\\u060c \\u062a\\u0636\\u0627\\u0639\\u0641\\u062a \\u0647\\u0630\\u0647 \\u0627\\u0644\\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u0628\\u0623\\u0643\\u062b\\u0631 \\u0645\\u0646 13 \\u0645\\u0631\\u0629 \\u0641 \\u0639\\u0627\\u0645 \\u0648\\u0627\\u062d\\u062f\\u060c \\u0648\\u0641\\u0642\\u064b\\u0627 \\u0644\\u0628\\u064a\\u0627\\u0646\\u0627\\u062a \\u0648\\u0632\\u0627\\u0631\\u0629 \\u0627\\u0644\\u0627\\u0642\\u062a\\u0635\\u0627\\u062f \\u0648\\u0627\\u0644\\u062a\\u062c\\u0627\\u0631\\u0629 \\u0627\\u0644\\u0625\\u0633\\u0628\\u0627\\u0646\\u064a\\u0629.\\n\\u0648\\u062d\\u0633\\u0628 \\u0627\\u0644\\u0645\\u0635\\u062f\\u0631 \\u0630\\u0627\\u062a\\u0647\\u060c \\u0628\\u0644\\u063a\\u062a \\u0642\\u064a\\u0645\\u0629 \\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u0627\\u0644\\u0623\\u0633\\u0644\\u062d\\u0629 \\u0645\\u0646 \\u0625\\u0633\\u0628\\u0627\\u0646\\u064a\\u0627 \\u0625\\u0644\\u0649 \\u0627\\u0644\\u0645\\u063a\\u0631\\u0628 \\u062d\\u0648\\u0627\\u0644\\u064a 21 \\u0645\\u0644\\u064a\\u0648\\u0646 \\u064a\\u0648\\u0631\\u0648\\u060c \\u0645\\u0642\\u0627\\u0631\\u0646\\u0629 \\u0628\\u06401.5 \\u0645\\u0644\\u064a\\u0648\\u0646 \\u064a\\u0648\\u0631\\u0648 \\u0641\\u064a \\u0639\\u0627\\u0645 2023. \\u0648\\u0634\\u0645\\u0644\\u062a \\u0645\\u0628\\u064a\\u0639\\u0627\\u062a \\u0627\\u0644\\u0645\\u0639\\u062f\\u0627\\u062a \\u0630\\u0627\\u062a \\u0627\\u0644\\u0637\\u0627\\u0628\\u0639 \\u0627\\u0644\\u0639\\u0633\\u0643\\u0631\\u064a \\u0642\\u0637\\u0639 \\u0623\\u0633\\u0644\\u062d\\u0629 \\u062e\\u0641\\u064a\\u0641\\u0629.\\n\\u0648\\u062a\\u0636\\u0645\\u0646\\u062a \\u0634\\u062d\\u0646\\u0627\\u062a \\u0627\\u0644\\u0623\\u0633\\u0644\\u062d\\u0629 \\u0645\\u0646 \\u0625\\u0633\\u0628\\u0627\\u0646\\u064a\\u0627 \\u0625\\u0644\\u0649 \\u0627\\u0644\\u0645\\u063a\\u0631\\u0628\\u060c \\u0627\\u0644\\u0642\\u0646\\u0627\\u0628\\u0644 \\u0627\\u0644\\u064a\\u062f\\u0648\\u064a\\u0629 \\u0648\\u0627\\u0644\\u0637\\u0648\\u0631\\u0628\\u064a\\u062f\\u0627\\u062a\\u060c \\u0627\\u0644\\u0628\\u0646\\u0627\\u062f\\u0642 \\u0648\\u0627\\u0644\\u0645\\u0633\\u062f\\u0633\\u0627\\u062a. \\u0641\\u064a\\u0645\\u0627 \\u0628\\u0644\\u063a\\u062a \\u0642\\u064a\\u0645\\u0629 \\u0635\\u0627\\u062f\\u0631\\u0627\\u062a \\u0627\\u0644\\u0623\\u0633\\u0644\\u062d\\u0629 \\u0627\\u0644\\u0625\\u0633\\u0628\\u0627\\u0646\\u064a\\u0629 \\u0625\\u0644\\u0649 \\u062f\\u0648\\u0644 \\u0627\\u0644\\u0639\\u0627\\u0644\\u0645 \\u062a\\u0642\\u0631\\u064a\\u0628\\u0627 858.4 \\u0645\\u0644\\u064a\\u0648\\u0646 \\u064a\\u0648\\u0631\\u0648\\u060c \\u0641\\u064a \\u062d\\u064a\\u0646 \\u0628\\u0644\\u063a\\u062a \\u0642\\u064a\\u0645\\u0629 \\u0627\\u0644\\u0648\\u0627\\u0631\\u062f\\u0627\\u062a 290.76 \\u0645\\u0644\\u064a\\u0648\\u0646 \\u064a\\u0648\\u0631\\u0648.\",\n          \"\\u0623\\u0646\\u0633 \\u0627\\u0644\\u0639\\u0645\\u0631\\u064a-\\u0643\\u0648\\u062f///\\n\\u0623\\u0648\\u0642\\u0641\\u062a \\u0645\\u0635\\u0627\\u0644\\u062d \\u0627\\u0644\\u0634\\u0631\\u0637\\u0629 \\u0627\\u0644\\u0642\\u0636\\u0627\\u0626\\u064a\\u0629 \\u0627\\u0644\\u062a\\u0627\\u0628\\u0639\\u0629 \\u0644\\u0645\\u0641\\u0648\\u0636\\u064a\\u0629 \\u0627\\u0644\\u0634\\u0631\\u0637\\u0629 \\u0628\\u062a\\u0646\\u063a\\u064a\\u0631\\u060c \\u0627\\u0644\\u064a\\u0648\\u0645 \\u0627\\u0644\\u062e\\u0645\\u064a\\u0633\\u060c \\u0628\\u0628\\u0648\\u0645\\u0627\\u0644\\u0646 \\u062f\\u0627\\u062f\\u0633 (\\u0625\\u0642\\u0644\\u064a\\u0645 \\u062a\\u0646\\u063a\\u064a\\u0631)\\u060c \\u0645\\u0648\\u0627\\u0637\\u0646\\u0627 \\u0641\\u0631\\u0646\\u0633\\u064a\\u0627 \\u064a\\u0628\\u0644\\u063a \\u0645\\u0646 \\u0627\\u0644\\u0639\\u0645\\u0631 48 \\u0633\\u0646\\u0629\\u060c \\u064a\\u0634\\u0643\\u0644 \\u0645\\u0648\\u0636\\u0648\\u0639 \\u0623\\u0645\\u0631 \\u062f\\u0648\\u0644\\u064a \\u0628\\u0625\\u0644\\u0642\\u0627\\u0621 \\u0627\\u0644\\u0642\\u0628\\u0636 \\u0635\\u0627\\u062f\\u0631 \\u0639\\u0646 \\u0627\\u0644\\u0633\\u0644\\u0637\\u0627\\u062a \\u0627\\u0644\\u0642\\u0636\\u0627\\u0626\\u064a\\u0629 \\u0627\\u0644\\u0641\\u0631\\u0646\\u0633\\u064a\\u0629.\\n\\u0648\\u062a\\u0634\\u062f \\u0627\\u0644\\u0645\\u0648\\u0627\\u0637\\u0646 \\u0627\\u0644\\u0641\\u0631\\u0646\\u0633\\u064a \\u0628\\u0646\\u0627\\u0621 \\u0639\\u0644\\u0649 \\u0645\\u0639\\u0644\\u0648\\u0645\\u0627\\u062a \\u062f\\u0642\\u064a\\u0642\\u0629 \\u0648\\u0641\\u0631\\u062a\\u0647\\u0627 \\u0645\\u0635\\u0627\\u0644\\u062d \\u0627\\u0644\\u0645\\u062f\\u064a\\u0631\\u064a\\u0629 \\u0627\\u0644\\u0639\\u0627\\u0645\\u0629 \\u0644\\u0645\\u0631\\u0627\\u0642\\u0628\\u0629 \\u0627\\u0644\\u062a\\u0631\\u0627\\u0628 \\u0627\\u0644\\u0648\\u0637\\u0646\\u064a\\u060c \\u0636\\u0645\\u0646 \\u0639\\u0645\\u0644\\u064a\\u0629 \\u0623\\u0645\\u0646\\u064a\\u0629 \\u062c\\u0631\\u0649 \\u062a\\u0646\\u0641\\u064a\\u0630\\u0647\\u0627 \\u0628\\u0628\\u0648\\u0645\\u0627\\u0644\\u0646 \\u062f\\u0627\\u062f\\u0633\\u060c \\u0628\\u0639\\u062f\\u0645\\u0627 \\u0643\\u0634\\u0641\\u062a \\u0639\\u0645\\u0644\\u064a\\u0629 \\u062a\\u0646\\u0642\\u064a\\u0637\\u0647 \\u0628\\u0642\\u0627\\u0639\\u062f\\u0629 \\u0628\\u064a\\u0627\\u0646\\u0627\\u062a \\u0627\\u0644\\u0645\\u0646\\u0638\\u0645\\u0629 \\u0627\\u0644\\u062f\\u0648\\u0644\\u064a\\u0629 \\u0644\\u0644\\u0634\\u0631\\u0637\\u0629 \\u0627\\u0644\\u062c\\u0646\\u0627\\u0626\\u064a\\u0629 (\\u0625\\u0646\\u062a\\u0631\\u0628\\u0648\\u0644) \\u0623\\u0646\\u0647 \\u0645\\u0637\\u0644\\u0648\\u0628 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0635\\u0639\\u064a\\u062f \\u0627\\u0644\\u062f\\u0648\\u0644\\u064a \\u0628\\u0645\\u0648\\u062c\\u0628 \\u0646\\u0634\\u0631\\u0629 \\u062d\\u0645\\u0631\\u0627\\u0621\\u060c \\u062a\\u0645 \\u062a\\u0639\\u0645\\u064a\\u0645\\u0647\\u0627 \\u0648\\u0646\\u0634\\u0631\\u0647\\u0627 \\u0645\\u0646 \\u0637\\u0631\\u0641 \\u0627\\u0644\\u0633\\u0644\\u0637\\u0627\\u062a \\u0627\\u0644\\u0642\\u0636\\u0627\\u0626\\u064a\\u0629 \\u0627\\u0644\\u0641\\u0631\\u0646\\u0633\\u064a\\u0629.\\n\\u0648\\u0628\\u062a\\u0639\\u0644\\u064a\\u0645\\u0627\\u062a \\u0645\\u0646 \\u0648\\u0643\\u064a\\u0644 \\u0627\\u0644\\u0645\\u0644\\u0643 \\u0644\\u062f\\u0649 \\u0627\\u0644\\u0645\\u062d\\u0643\\u0645\\u0629 \\u0627\\u0644\\u0627\\u0628\\u062a\\u062f\\u0627\\u0626\\u064a\\u0629 \\u0628\\u062a\\u0646\\u063a\\u064a\\u0631 \\u062a\\u0645 \\u0627\\u0644\\u0627\\u062d\\u062a\\u0641\\u0627\\u0638 \\u0628\\u0627\\u0644\\u0645\\u0648\\u0642\\u0648\\u0641 \\u062a\\u062d\\u062a \\u062a\\u062f\\u0628\\u064a\\u0631 \\u0627\\u0644\\u062d\\u0631\\u0627\\u0633\\u0629 \\u0627\\u0644\\u0646\\u0638\\u0631\\u064a\\u0629\\u060c \\u0639\\u0644\\u0649 \\u0630\\u0645\\u0629 \\u0645\\u0633\\u0637\\u0631\\u0629 \\u0627\\u0644\\u062a\\u0633\\u0644\\u064a\\u0645\\u060c \\u0628\\u0627\\u0644\\u0645\\u0648\\u0627\\u0632\\u0627\\u0629 \\u0645\\u0639 \\u0625\\u0634\\u0639\\u0627\\u0631 \\u0627\\u0644\\u0633\\u0644\\u0637\\u0627\\u062a \\u0627\\u0644\\u0623\\u0645\\u0646\\u064a\\u0629 \\u0627\\u0644\\u0641\\u0631\\u0646\\u0633\\u064a\\u0629 \\u0628\\u0647\\u0630\\u0627 \\u0627\\u0644\\u062a\\u0648\\u0642\\u064a\\u0641\\u060c \\u0648\\u0630\\u0644\\u0643 \\u0642\\u0635\\u062f \\u0625\\u0631\\u0633\\u0627\\u0644 \\u0645\\u0644\\u0641 \\u0627\\u0644\\u062a\\u0633\\u0644\\u064a\\u0645.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2d96ece2-f637-4a76-83ba-ad028a5a6878\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>كود – كازا ///\\nقالت وكالة إيفي الإسبانية، إن ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>أنس العمري – كود///\\nطائرة (Akıncı) بدون طيار،...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>أنس العمري-كود///\\nأوقفت مصالح الشرطة القضائية...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>كود سبور//\\nطلب محمد جودار نائب رئيس الجامعة ا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>كود – كازا ///\\nقالت جريدة أوكدياريو الإسبانية...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d96ece2-f637-4a76-83ba-ad028a5a6878')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d96ece2-f637-4a76-83ba-ad028a5a6878 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d96ece2-f637-4a76-83ba-ad028a5a6878');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e5707af-2e71-4f6b-825f-0595a9a051a0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e5707af-2e71-4f6b-825f-0595a9a051a0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e5707af-2e71-4f6b-825f-0595a9a051a0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             content\n",
              "0  كود – كازا ///\\nقالت وكالة إيفي الإسبانية، إن ...\n",
              "1  أنس العمري – كود///\\nطائرة (Akıncı) بدون طيار،...\n",
              "2  أنس العمري-كود///\\nأوقفت مصالح الشرطة القضائية...\n",
              "3  كود سبور//\\nطلب محمد جودار نائب رئيس الجامعة ا...\n",
              "4  كود – كازا ///\\nقالت جريدة أوكدياريو الإسبانية..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# take a look in our dataset using pandas\n",
        "ds.to_pandas().head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8e5f119",
      "metadata": {
        "id": "c8e5f119"
      },
      "source": [
        "3. split our dataset into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c7610d3",
      "metadata": {
        "id": "9c7610d3",
        "outputId": "ea7e1468-8cfd-4454-cbfc-1af09b498b43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['content'],\n",
              "        num_rows: 4\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['content'],\n",
              "        num_rows: 2\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ds_spliter=ds.train_test_split(test_size=0.2,seed=42)\n",
        "ds_spliter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8baab2d4",
      "metadata": {
        "id": "8baab2d4"
      },
      "source": [
        "# Preprocessing For Pretraining LM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e43fad7",
      "metadata": {
        "id": "0e43fad7"
      },
      "source": [
        "> In this step we will go through the necessary preprocessing steps befor starting train."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b2714a2",
      "metadata": {
        "id": "4b2714a2"
      },
      "source": [
        "1. select the base model you want to train from hf 🤗\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d190302",
      "metadata": {
        "id": "8d190302"
      },
      "outputs": [],
      "source": [
        "model_id=\"HuggingFaceTB/SmolLM2-135M-Instruct\" # example HuggingFaceTB/SmolLM2-135M-Instruct"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93b49a08",
      "metadata": {
        "id": "93b49a08"
      },
      "source": [
        "2. load model tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2b67039",
      "metadata": {
        "id": "b2b67039",
        "outputId": "b1d0f74e-80e5-4d05-84fa-c4e7cd859807",
        "colab": {
          "referenced_widgets": [
            "afe42e6011664aeb9dabf69138471c59",
            "840f881140184b1f80192680c0d9e434",
            "ab3f5aa64584453ea01a3e0938618396",
            "5328a7f8b6a94d33a305b931691a0fc1",
            "dddd45e907bd478a801d431b95ab1278"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afe42e6011664aeb9dabf69138471c59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.76k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "840f881140184b1f80192680c0d9e434",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab3f5aa64584453ea01a3e0938618396",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5328a7f8b6a94d33a305b931691a0fc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dddd45e907bd478a801d431b95ab1278",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/655 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d28c590a",
      "metadata": {
        "id": "d28c590a"
      },
      "source": [
        "3. check some tokenizer configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69ac817e",
      "metadata": {
        "id": "69ac817e",
        "outputId": "663a7838-e8d2-4047-c373-307fe5eb7750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49152\n",
            "8192\n",
            "{'bos_token': '<|im_start|>', 'eos_token': '<|im_end|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|im_end|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}\n"
          ]
        }
      ],
      "source": [
        "# check the vocabe size of our tokenizer\n",
        "print(f\"{len(tokenizer)}\")\n",
        "# model max length (means the max len of the input)\n",
        "print(f\"{tokenizer.model_max_length}\")\n",
        "# tokenizer special tokens\n",
        "print(tokenizer.special_tokens_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. test tokenizer\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://postimage.me/images/2025/05/21/image86e1221de90dba5d.png\" width=600 />\n",
        "</center>"
      ],
      "metadata": {
        "id": "px2G-IWiYVrO"
      },
      "id": "px2G-IWiYVrO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e0ba308",
      "metadata": {
        "id": "7e0ba308",
        "outputId": "0e078628-0552-4d2b-86d6-a59f5fe6eb7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[19556, 957, 1462, 1792, 339, 5248, 6545, 13701, 15634]\n",
            "['Hello', 'Ġmy', 'Ġname', 'Ġx', 'ĠI', \"'m\", 'ĠThink', 'AI', 'Ġparticipant']\n",
            "Hello my name x I'm ThinkAI participant\n"
          ]
        }
      ],
      "source": [
        "example=\"Hello my name x I'm ThinkAI participant\"\n",
        "ids=tokenizer.encode(example)\n",
        "print(ids)\n",
        "tokens=tokenizer.convert_ids_to_tokens(ids)\n",
        "print(tokens)\n",
        "decode_=tokenizer.decode(ids)\n",
        "print(decode_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> After learned about Tokenizer, now we will go through encode our input text. the only things we need to fix is the `context length`and it should be less than or equal the `model_max_length`.\n",
        "* Big `context length` means more context\n",
        "* More `context length` more GPU memory\n",
        "* `contenxt length` Recommended to be in **%64** `[64,128,256,...max_length]` to train you model faster try to use 128.\n",
        "* all input ids will **turncated** to be in selected `context length`\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://postimage.me/images/2025/05/21/image3f9f198e4dab5af7.png\" width=600 />\n",
        "</center>"
      ],
      "metadata": {
        "id": "0IzPGN_NY1j-"
      },
      "id": "0IzPGN_NY1j-"
    },
    {
      "cell_type": "markdown",
      "id": "13f9fa34",
      "metadata": {
        "id": "13f9fa34"
      },
      "source": [
        "4. set context length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee81b7e3",
      "metadata": {
        "id": "ee81b7e3"
      },
      "outputs": [],
      "source": [
        "context_length=128"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d639892",
      "metadata": {
        "id": "4d639892"
      },
      "source": [
        "5. tokenize function\n",
        "\n",
        "> with tokenize function we will tokenize all the text input and truncate it to be in the same `context_length`, and finally we will keep only the input ids with `length == context_lenght`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94ad9596",
      "metadata": {
        "id": "94ad9596"
      },
      "outputs": [],
      "source": [
        "def tokenize(examples):\n",
        "  results=tokenizer(\n",
        "      examples[\"content\"],\n",
        "      truncation=True,\n",
        "      max_length=context_length,\n",
        "      return_overflowing_tokens=True, # with this you will get also the input ids with length less than context_length\n",
        "      return_length=True\n",
        "  )\n",
        "  input_batch=[]\n",
        "  for l,in_ids in zip(results[\"length\"],results[\"input_ids\"]):\n",
        "    if l==context_length:\n",
        "      input_batch.append(in_ids)\n",
        "  return {\"input_ids\":input_batch}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd0570c3",
      "metadata": {
        "id": "dd0570c3"
      },
      "source": [
        "> After creating the tokenize function now we will tokenize all text using `map()` method by datasets. after tokenized you text dataset the number of rows will increase cause of each example will have `context_size`.\n",
        "* we need only the input_ids column to train our model, that's why we need to remove the others with `remove_columns` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c238c5b",
      "metadata": {
        "id": "1c238c5b",
        "outputId": "fe6cc46c-f2e5-4694-d02c-36f29553dc78",
        "colab": {
          "referenced_widgets": [
            "c8800125de7848a59015fded5cc072b7",
            "4541e689586f4bbdace1d9f4775fe32c"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8800125de7848a59015fded5cc072b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4541e689586f4bbdace1d9f4775fe32c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_ds=ds_spliter.map(tokenize,batched=True,remove_columns=ds_spliter[\"train\"].column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> now the last step in data preprocessing is to generate batches and labels using `DataCollatorForLanguageModeling`, the main roles of this function is:\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://postimage.me/images/2025/05/21/image9231cd4e1c93a453.png\" width=600 />\n",
        "</center>\n",
        "\n",
        "* Create batches\n",
        "* Add Padding to batches (Inputs are dynamically padded to the maximum length of a batch if they are not all of the same length.)\n",
        "* Creating Labels\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://postimage.me/images/2025/05/21/image542309b0390d25e5.png\" width=600 />\n",
        "</center>\n",
        "\n",
        "* Masked % from text when we train Masked Language Model (MLM) models. (in our case `mlm=False`)"
      ],
      "metadata": {
        "id": "QLTeCwp7ZFjW"
      },
      "id": "QLTeCwp7ZFjW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "086af3a6",
      "metadata": {
        "id": "086af3a6"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5571160f",
      "metadata": {
        "id": "5571160f"
      },
      "source": [
        "# Load & Train Your Selected Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8d1e613",
      "metadata": {
        "id": "a8d1e613"
      },
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> After preprocessing stage, now we are ready to train our model, but first of all we need to select which method we want to use as explained above [first section].\n",
        "\n",
        "* training from scratch (RPT)\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://postimage.me/images/2025/05/21/image728ebde6a6828be1.png\" width=600 />\n",
        "</center>\n",
        "\n",
        "```\n",
        "  *  will load model and init weights with random values\n",
        "  1. load model configs using AutoConfig.form_pretrained\n",
        "  2. load model architect using AutoModelForCausalLM.from_config\n",
        "```\n",
        "\n",
        "* continuos training (CPT)\n",
        "\n",
        "<center>\n",
        "\n",
        "<img src=\"https://postimage.me/images/2025/05/21/image5a072f44cf0f9ca2.png\" width=600 />\n",
        "</center>\n",
        "\n",
        "```\n",
        "  * will load the model with trained weights\n",
        "  1. load model  and weights using AutoModelForCausalLM.form_pretrained\n",
        "```\n",
        "\n",
        "the difference between those 2 methods is only on loading model code."
      ],
      "metadata": {
        "id": "1OYKMQqMZ2vH"
      },
      "id": "1OYKMQqMZ2vH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb951007",
      "metadata": {
        "id": "eb951007",
        "outputId": "5f795ce3-212d-4784-d4ae-d113d9b1c80a",
        "colab": {
          "referenced_widgets": [
            "495e8b1543ea46fca964554554944780"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "495e8b1543ea46fca964554554944780",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/861 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM,AutoConfig\n",
        "config=AutoConfig.from_pretrained(model_id)\n",
        "model=AutoModelForCausalLM.from_config(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7fa8d2b",
      "metadata": {
        "id": "a7fa8d2b"
      },
      "source": [
        "### Train Args"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b7267ce",
      "metadata": {
        "id": "9b7267ce"
      },
      "source": [
        "> Now in the last step before training, we should set the training arguments, and the important one is:\n",
        "* `output_dir` [dir to save the model checkpoints]\n",
        "* `num_train_epochs`\n",
        "* `learning_rate`\n",
        "* `lr_scheduler_type` [linear/cosine]\n",
        "* `batch_size` [train/eval]\n",
        "* `warmup_steps` [increase lr from low val to target value during the begining x steps]\n",
        "* `save_steps` [save every x steps]\n",
        "* `save_total_limit` [save only x checkpoints to avoid memory space :( ]\n",
        "* `fp16` [mixed-precision training]\n",
        "* `push_to_hub` [push the trained model to the hub after finishing]\n",
        "* `logging_steps` [show logs (loss/accuracy) after x steps]\n",
        "* `report_to` [we will use wand]\n",
        "* `...`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "360cfaee",
      "metadata": {
        "id": "360cfaee"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "args=TrainingArguments(\n",
        "    output_dir=\"test_dir\",\n",
        "    num_train_epochs=2,\n",
        "    per_device_eval_batch_size=8,\n",
        "    per_device_train_batch_size=8,\n",
        "    learning_rate=5e-4,\n",
        "    warmup_steps=100,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    fp16=False,\n",
        "    logging_steps=2,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"wandb\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84c4c872",
      "metadata": {
        "id": "84c4c872"
      },
      "source": [
        "### Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f9a3cd4",
      "metadata": {
        "id": "7f9a3cd4"
      },
      "source": [
        "> After setting Training args now we will connect everthing using `Trainer` and then initialize the training using `trainer.train()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66af4ab6",
      "metadata": {
        "id": "66af4ab6",
        "outputId": "e4cb0251-8237-4bd4-f7af-a1b4e34e1971"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-24-f148329c4a9d>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer=Trainer(\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer\n",
        "trainer=Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_ds[\"train\"],\n",
        "    eval_dataset=tokenized_ds[\"test\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2716ac74",
      "metadata": {
        "id": "2716ac74",
        "outputId": "14d79ec6-979d-4a88-949a-801b182d566d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mth3elma2\u001b[0m (\u001b[33mth3elma2-enset-mohammedia\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250322_173545-46apf9jw</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/th3elma2-enset-mohammedia/huggingface/runs/46apf9jw' target=\"_blank\">test_dir</a></strong> to <a href='https://wandb.ai/th3elma2-enset-mohammedia/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/th3elma2-enset-mohammedia/huggingface' target=\"_blank\">https://wandb.ai/th3elma2-enset-mohammedia/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/th3elma2-enset-mohammedia/huggingface/runs/46apf9jw' target=\"_blank\">https://wandb.ai/th3elma2-enset-mohammedia/huggingface/runs/46apf9jw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8/8 00:13, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>11.202200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>11.236400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>11.178200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>11.055600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8, training_loss=11.168097734451294, metrics={'train_runtime': 33.6865, 'train_samples_per_second': 1.662, 'train_steps_per_second': 0.237, 'total_flos': 4567598235648.0, 'train_loss': 11.168097734451294, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c1182ad",
      "metadata": {
        "id": "1c1182ad"
      },
      "source": [
        "## What Did We Learn? 📚\n",
        "\n",
        "In this notebook, you learned:\n",
        "1. How to prepare text for a language model\n",
        "2. How to set up and train a small language model\n",
        "3. How to monitor the training process\n",
        "\n",
        "\n",
        "## Next Steps 🎯\n",
        "\n",
        "Want to learn more? Check out:\n",
        "1. How to make your model follow instructions\n",
        "2. How to make your model smaller and faster\n",
        "3. How to use your trained model for cool projects"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38266e16",
      "metadata": {
        "id": "38266e16"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "> Here are the most important and common metrics that you will likely need before launching your LLM system into production:\n",
        "* **Answer Relevancy:** Determines whether an LLM output is able to address the given input in an informative and concise manner.\n",
        "* **Correctness:** Determines whether an LLM output is factually correct based on some ground truth.\n",
        "* **Hallucination:** Determines whether an LLM output contains fake or made-up information."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7c1862d",
      "metadata": {
        "id": "a7c1862d"
      },
      "source": [
        "* challenge evaluation\n",
        "\n",
        "- quiz\n",
        "- training / valid loss\n",
        "- example prompt"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}